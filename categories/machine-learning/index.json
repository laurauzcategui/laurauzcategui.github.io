[
    {
        "ref": "https://laurauzcategui.github.io/blog/machine-learning/ml_types/",
        "title": "Types of Machine Learning",
        "section": "blog",
        "tags": ["Machine Learning","AI"],
        "date" : "2020.07.02",
        "body": "It\u0026rsquo;s been a while since I wrote my first post on What is Machine Learning (ML) and How Programming paradigms have changed over time and describing some use cases/applications. This time, I am sharing how Machine Learning and AI can be seen from different perspectives, specifically covering the following two areas:\n How much human interaction is involved in the training process of different ML algorithms. How the training is performed.   Before moving into each of these areas, let\u0026rsquo;s clarify a few concepts around the Machine Learning Process. If you are familiar with how Machine Learning works, you can skip this section.\nA high-level definition of Machine Learning can be seen as:\n Given some data representative of an area ( sales, politics, education) you are analysing and an algorithm, the ability of a computer can learn from this data and detect certain patterns on it. Followed by being able to tell (predict ) you and determine the type of new data or at least an approximation of it.  Take this concept with a pinch of salt, as there is too much involved in the background about how ML is actually performed.\nIn other words, the computer is able to detect patterns by training ( learning ) from the input data. This process is highly iterative and needs lots of tuning. For example: It needs to check how far or close the prediction is from the real value, then correct itself by adjusting its parameters until reaching a point where the model is certainly accurate enough to be used.\nOk, now that we have an overview of the process. Let\u0026rsquo;s jump into types of Machine Learning.\nML Algorithms and Human intervention. Machine Learning systems on this area could be seen as the amount of \u0026ldquo;Supervision\u0026rdquo; a.k.a Human Interaction those will have over the training process. These are divided in 3 main categories, I will try to illustrate the following definitions with examples.\n1. Supervised Learning Imagine you are the owner of a local bookshop.\n Your daughter Ana is a Data Scientist and she has offered to take books dataset recorded in your inventory system and implement a new system to speed up registration of new books arriving for sale.\nAna knows some characteristics of the books:\n Genre ( Fiction, Non-Fiction, Fantasy, Thriller ) Hardcover, if a books is available on Hardcover ISBN, the commercial id for the book. Title, Number of Pages Extract of the book or Cover picture Author  Now, Imagine having to allocate one book in a bookshelf. This is easy if you look up the metadata online and place the book on the Fiction shelf.\nHowever, in reality, if you receive upto 200 books per day, you cannot do this job on your own, manually entering data on the system is error prone and you might end up putting books in the wrong shelf. This misplacement might end up in lower revenue as when a new customer comes incomes in and leaves unsatisfied because they cannot find the book even though it was actually on the store.\nAna\u0026rsquo;s new system is as easy as feeding the system with an extract or the cover of the book you are looking for and can tell you which shelf this should be placed on.\nThis particular example is called: Classification, because the system is just helping you to classify (organise) some data based on certain characteristics that you as user presented to it.\nA real example of this kind of system is: Google Photos.\nYet another type of Supervised algorithm is about predicting a numeric value, given a set of features or characteristics called predictors.\nNow, you might actually ask how this happens?\nAn example of this is using Regression. A common and widely used algorithm known as Linear Regression and the purpose is to predict a continuous value as a result.\nThis actually translates to having a set of features or variables, and a set of labels that match this input features and all you want the algorithm to do is to learn how to \u0026ldquo;fit\u0026rdquo; the weights (parameters) associated with these features to give the approximate value that is closer to the real value.\n2. Unsupervised Learning. Unsupervised algorithms cover all cases when we do not have a label or real value to compare against. Instead we do have sets of data, and the model will be trained and predicted based on how the data is grouped together, how it detects patterns and if it shows certain behaviours.\nA typical example for this type of Machine Learning is Clustering, where you group your data based on similarity. Real examples include Recommender Systems such as:\n Retailer websites, like Amazon and Zalando. Media / Streaming systems, like Netflix, Youtube among others.  There are lots of other algorithms that are used within this type, for example Anomaly detection which might cover credit card fraud or account takeover situations that can be prevented and predicted with the use of ML.\nYet another of my favourite types of unsupervised learning algorithms that I\u0026rsquo;ve discovered recently are those used for data visualization, like t-SNE or t-Distributed Stochastic Neighbor Embedding.\nI have used t-SNE in a couple of pet projects for sentiment analysis visualization and you could actually see the clusters forming within itself in high dimensional space using at the same time dimensionality reduction.\n3. Reinforcement Learning. Many books and websites refer to these algorithms like \u0026ldquo;the beast\u0026rdquo; but I like thinking about it about the top of the ice cream. Currently being a trending topic due to the achievements that are being accomplished in the area, which I will mention in a bit.\nWhat would you do in this case? Most likely, you will play a couple of times, trying to investigate what are the best movements and the best route you can use to finally rescue the dogs from the shelter. This is similar to what a reinforcement algorithm will do, you can think of it as the following:\n You are given an environment. (space in the context of the video game), representative of the state of certain variables on the space. Like roadblocks or crickets falling from the sky. Actions to be performed during the event. ( movements, like going up, down, throw a ball to builders ), it\u0026rsquo;s worth noticing that some actions could be rewarded as \u0026ldquo;good\u0026rdquo;, and some others as \u0026ldquo;bad\u0026rdquo; meaning it will decrease your ability to achieve the goal. Agents (roles in the video game, rescuer or, builder), the ones who will perform the action to achieve the goal at the minimum cost possible.  The way it works is the Agent observes the environment, tries to perform actions, and based on these actions will get rewarded for them or not. Potentially the Agents will learn on their own what is the best approach/strategy to pursue in order to get the maximum amount of points (rewards).\nOne of the best systems I\u0026rsquo;ve seen so far built with it are:\n  Hide and Seek, developed by OpenAI. Where they use a multi-agent approach teaching those to play hide and seek. There are 2 agents \u0026ldquo;hiders\u0026rdquo; and \u0026ldquo;seekers\u0026rdquo; and by observing the environment they were able to learn behaviour/actions that weren\u0026rsquo;t even provided, like using obstacles to pass barriers. If you are curious about how it works in depth you can watch the video below and the paper.\n     Video Games, like StarCraf or AlphaStar. The agents play against humans and indeed it beat the best world player or beat other agents in a matter or couple of seconds. In order to achieve this, the group that developed AlphaStar didn\u0026rsquo;t only use Reinforcement learning but others like using Supervised learning to train the neural networks that will create the instructions to play the game. If you are curious about how it done, you can check their blog post here\n  We have learned by now different types of Machine Learning systems based on how little or much the human interaction with those systems is applied. Now we can go ahead and explore the next 2.\n ML Algorithms and Training process. In previous sections, we outlined that the training process is how your algorithm will \u0026ldquo;learn\u0026rdquo; the best parameters to make a prediction. Having said that, training itself is an art and can be performed differently depending on the use case, resources available, and the data itself.\nThis is divided in two:\n Batch Learning Online Learning, also known as Incremental Learning.  Let\u0026rsquo;s see how those work:\n1. Batch Learning. Batch learning is about training your model with all the data that is available at once rather than doing it incrementally. Usually performing this action takes a lot of time. Imagine having to train Terabytes if not bigger of data all at once. But why would you need to do that? Due to the nature of the Business or use case, for example, reports or decisions that are delivered with a certain frequency like weekly/monthly might not need training on a real-time basis. This type of training is usually done offline, as it takes a very long time (hours/days/weeks) to complete.\nHow does training occur?  The model is trained. The model gets deployed and launched to Production. The model is running continuously without further \u0026ldquo;learning\u0026rdquo;.  All this process is called offline learning. Now you might wonder, what happens if my data or use case has changed? You need to train your model again against incorporating the new data or features.\nA practical example, in my previous job models were deployed to production in a batch learning fashion and some models didn\u0026rsquo;t need to be refreshed so often, so It could happen once every week or so. Yet another reason to generate a new model was by looking at metrics deployed in the monitoring system and checking if the performance of the model was being degraded.\nThese types of models are tightly related to resources such as IO,CPU, Memory or Network among others, so having this in mind before deciding on which approach to take is hugely important. Nowadays this might be really expensive but at the same time, you could take advantage of Cloud platforms offering solutions out of the box for doing this, such as: AWS Batch ,Azure Machine Learning - Batch Prediction, or Google Cloud AI Platform.\nMoving on, let’s talk now about Online Learning\nOnline Learning Have you wondered how Netflix, Disney, Amazon Prime Video are recommending you what to watch? Or Why Zalando and Amazon keep telling you to buy these amazing trousers that might go with a pair of white shoes? You are probably telling, yeah Recommender Systems, but more than that, how it can be done so quickly? How does the system adapt so quickly to change?\nYou probably got it right again, this is done because Training occurs on the fly, meaning data is processed as it\u0026rsquo;s arriving to the system. This approach is suitable for systems that are receiving data continuously, like retailers, or systems that need to adapt to changes quickly as well like a News website, or Stock market.\nIn terms of how training is performed is as follows:\n Data is chunked into pieces or mini-batches. Train the model ( continuously). Continuous evaluation / monitoring. Deployment to production.  One of the advantages of doing online learning is that if you don’t have enough computation resources or storage, you can discard the data as you train. Saving you then a huge deal of resources. On the other hand, if you need to replay the data you might want to store it for a certain amount of time.\nAs with every system we deal with, this type of training has its strengths and weaknesses. One of the downsides of dealing with this approach is that Performance of the model might degrade quickly or eventually as the data might change quickly you might notice drops in prediction accuracy at some point in time. For this reason and -barely a topic I have seen talked about often- is having in place good monitoring systems. Those will help your team or company to prevent and understand when to start changing or tuning the models to make them effective.\n Highlights You have come this far and I hope you have enjoyed it. Initially, we talked about how machine learning works to then dive into how Machine Learning is divided according to the perspective of Humans interact with the Algorithms. Ultimately, I tried to describe as much as possible each of these types Supervised, Unsupervised, and Reinforcement Learning with cool examples and applications I have seen around. I\u0026rsquo;ll probably start posting more practical things that I\u0026rsquo;ve learned on the journey and would love to share. #SharingIsCaring.\nStay well and see you soon.\n"
    }
,
    {
        "ref": "https://laurauzcategui.github.io/blog/machine-learning/index.json",
        "title": "Machine Learning",
        "section": "blog",
        "tags": null,
        "date" : "2020.06.30",
        "body": "Follow my journey through Machine Learning / Data Science.\n"
    }
,
    {
        "ref": "https://laurauzcategui.github.io/blog/machine-learning/what_is_ml/",
        "title": "On the Journey to Machine Learning / AI",
        "section": "blog",
        "tags": ["Machine Learning","AI"],
        "date" : "2019.12.30",
        "body": "This is my first blog on Machine Learning (ML) and my journey through it. I’ve been quite interested in all things data from the very beginning of my career as a Software Engineer.\nIf you are interested in following baby steps on the journey to ML, its fundamentals and how you could start building projects with it, tag along and I’ll do my best to explain what I’ve learned so far.\nI knew the future will be all about Data from the moment I started reading and learning more about Big Data, Data pipelines, Data Science, Artificial Intelligence.\nCertainly, I’m more convinced now when observing how that we ( humans ) are continuously massive producers of data and I cannot resist digging further about how, when, where we could take advantage of this new oil and get the most out of it.\nDisclaimer: the purpose of this post is to share the knowledge I’ve been getting meanwhile I study and work with Machine Learning. I’ll try to make references as much as I can to resources so you could take a look too if you wish to expand further.\nThe following post is composed in 3 sections, what is Machine Learning and how is it changing paradigms from a Software Engineering perspective, to finalize then on why everyone is so interested or not in getting it into their lives.\n What is Machine Learning ? There are millions of definitions about Machine Learning everywhere, I’ll point out here my favorite ones.\n The analogy with the human brain is used as a guiding principle \u0026hellip; The investigation mainly centres round an analogous teaching process applied to machines. Turing, A. (1948). Intelling Machinery, 1948.\n  A field of study that gives the computer(s) the ability to learn, without being explicitly programmed.\nArthur Samuel, 1959\n How do I define it? Machine Learning is an area of science that helps you to detect patterns at a faster speed than we humans could do with the help of course of computers. Imagine it like applying all your math knowledge to data and applying techniques to make possible to take those patterns and get answers out of the data you are giving as an Input to algorithms.\nHow the programming paradigm is shifting with ML ? If you are a Software Engineer, the following explanation might resonate with you.\nImagine you are building a smartwatch application that will help you to detect the type of workout you are doing at the gym, and as of now and for the purpose of this example your application only detects when you are using the treadmill or the stair stepper.\nGreat! You have built-in some rules in the backend of the application to detect if it’s using any of those machines and calculate the calories, as observed below:\nmax_speed_on_treadmill = 19 # 19 km/h max_speed_on_climber = 126 # 126 per minute if inclination \u0026gt; 2 and speed \u0026gt; 0 and speed \u0026lt; max_speed_on_treadmill: running_on_treadmill = True calculate_calories() elif steps_per_minute \u0026lt; max_speed_on_climber: using_stair_stepper = True calculate_calories() But, here is the catch:\n What would happen in 1 year when 5 more machines with different brands come into the market and the owner of the smartwatch start using one of these machines you haven’t added yet? What would happen when a Gym owner wants you to add all of his machines to your app, and he owns lots of brands and there are approx +20 machines? On top of these new restrictions, you also should account for the person who is doing the exercise, weight, heart rate…etc.  Ok, this seems like a lot of rules to code in the application. This paradigm is still used in many applications and still applies to the common use of programming, as explained below:\n Traditional Programming Paradigm Rules and Data are the Input and We get Answers as the output :) Example: You used today the treadmill for 15 minutes and your calories burned were 200 :)\n What if I told you that you could turn this around and let the computer figure it out the rules.\n New Programming Paradigm Data and Answers are fed into Algorithms and the outcome are the rules Example: You let the algorithm know what are the features for using:\n Machine A ( velocity, speed, inclination) and its values and you said: “This is what a Treadmill use looks like”. Machine B ( steps per minute, velocity, program ) and its values and you said: “This is what a Stair Stepper use looks like”.  And so on and so forth, you feed the algorithm with lots of examples. So next time the smartwatch owner uses a new machine your smartwatch will be able to infer is using a leg press and will calculate everything on its own.   How great is this? To be able to input data and let the computer figure it out the rules for you so you don’t have to spend hours of your time writing infinite rules ;-)\nNow, let’s dive into the last section of the post on which I’ll explain how useful this is and why do we want to actually use it.\nWhy do we want to use it? There is a lot of research being done around Intelligent Machines, and I have no doubts we might live at some point a new era of sharing our daily lives with those machines. We could even say we are doing it now with the presence of Smart Assistance, Recommendation Systems embedded in the software and applications we use daily, such as Netflix, Airbnb, Amazon between others, but still, I would say there are lots to be done and to experiment with.\nIf you have read about Machine Learning and Artificial Intelligence before, you might know there is a lot of controversy around this topic, specifically related to automation, machines taking our jobs and we all being fired due to the rise of Machine Intelligence. Well, let me tell you this is far from the truth.\nFrom my point of view, Machine Learning / Artificial Intelligence should be seen as a complement to our skills, to our strengths but also to our weakness, ultimately as a tool where we help the computer by building the model and the computer help us to do calculations at the speed we cannot.\nThe benefits I’ve seen so far in Business, Society, and Life are massive, a couple of examples here:\n The possibility to detect pneumonia from chest X-rays, a Deep Learning algorithm developed by Standford. Farmers Companion App, an application that helps to detect and identify when a crop has been infected by a caterpillar and advice you on how to treat it to stop it from happening.  The later is a good example of how we actually can make Machine Learning part of our lives and skills to boost our work and perhaps produce more with less in our business or simply a better world to live in. If you are more curious about what types of Machine Learning are around and how you could start thinking if it’s worth it or not to apply it to your business use cases, stick around and follow me as I’m planning to write more about it in next posts.\n"
    }
]
